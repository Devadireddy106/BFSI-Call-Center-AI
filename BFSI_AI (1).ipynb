{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Dataset preparation"
      ],
      "metadata": {
        "id": "y6qTzIsHEFmb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW0kwDCqymJ0"
      },
      "outputs": [],
      "source": [
        "import json, random, os\n",
        "\n",
        "os.makedirs(\"/content/drive/MyDrive/bfsi/data\", exist_ok=True)\n",
        "\n",
        "loan_amounts = [\"1 lakh\", \"2 lakh\", \"3 lakh\", \"5 lakh\", \"10 lakh\"]\n",
        "tenures = [\"12 months\", \"24 months\", \"36 months\", \"48 months\"]\n",
        "rates = [\"9%\", \"10%\", \"11%\", \"12%\", \"13%\"]\n",
        "\n",
        "dataset = []\n",
        "\n",
        "def add(inst, inp, out):\n",
        "    dataset.append({\n",
        "        \"instruction\": inst,\n",
        "        \"input\": inp,\n",
        "        \"output\": out\n",
        "    })\n",
        "\n",
        "# 1. Loan Eligibility (30)\n",
        "for i in range(30):\n",
        "    add(\n",
        "        \"Check loan eligibility\",\n",
        "        f\"My salary is ₹{random.randint(20000,80000)} per month\",\n",
        "        \"Based on your income details, you may be eligible for a personal loan. Final eligibility depends on credit score, repayment history, and internal policy checks. Kindly proceed with the application for confirmation.\"\n",
        "    )\n",
        "\n",
        "# 2. EMI Details (30)\n",
        "for i in range(30):\n",
        "    add(\n",
        "        \"Explain EMI details\",\n",
        "        f\"Loan {random.choice(loan_amounts)} for {random.choice(tenures)}\",\n",
        "        \"Your EMI will depend on the loan amount, tenure, and applicable interest rate. Once processed, the EMI schedule will be shared through your registered email and app dashboard.\"\n",
        "    )\n",
        "\n",
        "# 3. Interest Rates (30)\n",
        "for i in range(30):\n",
        "    add(\n",
        "        \"Provide interest rate information\",\n",
        "        \"What is the interest rate for personal loans?\",\n",
        "        \"Personal loan interest rates vary based on customer profile and credit assessment. Current rates generally start from competitive market levels. Please check the latest offers in your account portal.\"\n",
        "    )\n",
        "\n",
        "# 4. Payment Status (25)\n",
        "for i in range(25):\n",
        "    add(\n",
        "        \"Check payment status\",\n",
        "        \"Has my EMI been received?\",\n",
        "        \"You can verify your recent payment status in the transaction history section of the mobile app. If the payment was successful, it will reflect within 24 hours.\"\n",
        "    )\n",
        "\n",
        "# 5. Penalties (20)\n",
        "for i in range(20):\n",
        "    add(\n",
        "        \"Explain late payment penalty\",\n",
        "        \"What happens if I miss my EMI?\",\n",
        "        \"Delayed payments may attract late fees and additional interest as per policy. We recommend paying dues before the due date to avoid penalties and credit score impact.\"\n",
        "    )\n",
        "\n",
        "# 6. Transaction Queries (25)\n",
        "for i in range(25):\n",
        "    add(\n",
        "        \"Help with transaction issue\",\n",
        "        \"My payment is not reflected\",\n",
        "        \"If your payment is not visible, please allow standard processing time. If the issue persists beyond 24 hours, kindly contact customer support with the transaction reference number.\"\n",
        "    )\n",
        "\n",
        "# 7. Account Support (20)\n",
        "for i in range(20):\n",
        "    add(\n",
        "        \"Assist with account support\",\n",
        "        \"How do I update my mobile number?\",\n",
        "        \"You may update your registered mobile number through the profile section after completing OTP verification. For assistance, contact support.\"\n",
        "    )\n",
        "\n",
        "# 8. Insurance Queries (20)\n",
        "\n",
        "for i in range(20):\n",
        "    add(\n",
        "        \"Provide insurance policy details\",\n",
        "        \"What does my insurance cover?\",\n",
        "        \"Your policy coverage details are listed in the policy document. Please review the terms and conditions to understand inclusions, exclusions, and claim procedures.\"\n",
        "    )\n",
        "\n",
        "# Save file\n",
        "path = \"/content/drive/MyDrive/bfsi/data/alpaca_dataset.json\"\n",
        "with open(path, \"w\") as f:\n",
        "    json.dump(dataset, f, indent=2)\n",
        "\n",
        "print(\"Dataset saved at:\", path)\n",
        "print(\"Total samples:\", len(dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity Engine"
      ],
      "metadata": {
        "id": "vV1EE21_ErgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers faiss-cpu\n"
      ],
      "metadata": {
        "id": "DpE1oN6DzdJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset"
      ],
      "metadata": {
        "id": "ESjXW9ltE1gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "DATA_PATH = \"/content/drive/MyDrive/bfsi/data/alpaca_dataset.json\"\n",
        "with open(DATA_PATH) as f:\n",
        "    dataset = json.load(f)\n",
        "print(\"Dataset size:\", len(dataset))\n",
        "\n"
      ],
      "metadata": {
        "id": "zqSrEPjDzjEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Eambiddings+ FAISS Index"
      ],
      "metadata": {
        "id": "eemDb0eCE4Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "vtFVxn78zpAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# Use only user questions\n",
        "questions = [d[\"input\"] for d in dataset]\n",
        "\n",
        "embeddings = embed_model.encode(questions, show_progress_bar=True)\n",
        "\n",
        "#  normalize for cosine similarity\n",
        "embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "dim = embeddings.shape[1]\n",
        "\n",
        "# inner product index (cosine similarity)\n",
        "index = faiss.IndexFlatIP(dim)\n",
        "index.add(embeddings)\n",
        "\n",
        "print(\"FAISS index built:\", index.ntotal)\n",
        "\n"
      ],
      "metadata": {
        "id": "Zx1-udX_zzed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faiss.write_index(index, \"/content/drive/MyDrive/bfsi/data/faiss_cosine.index\")\n"
      ],
      "metadata": {
        "id": "D16X4New1vaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity Search Function"
      ],
      "metadata": {
        "id": "nRzKe3WcFaG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_search(query, threshold=0.70, top_k=3):\n",
        "    \"\"\"\n",
        "    Cosine similarity search\n",
        "    Returns best match from dataset\n",
        "    \"\"\"\n",
        "\n",
        "    q_emb = embed_model.encode([query])\n",
        "\n",
        "    # normalize\n",
        "    q_emb = q_emb / np.linalg.norm(q_emb, axis=1, keepdims=True)\n",
        "\n",
        "    scores, indices = index.search(q_emb, top_k)\n",
        "\n",
        "    best_score = scores[0][0]\n",
        "    best_idx = indices[0][0]\n",
        "\n",
        "    result = {\n",
        "        \"matched\": False,\n",
        "        \"response\": None,\n",
        "        \"score\": round(float(best_score), 3),\n",
        "        \"source\": \"None\"\n",
        "    }\n",
        "\n",
        "    if best_score >= threshold:\n",
        "        result[\"matched\"] = True\n",
        "        result[\"response\"] = dataset[best_idx][\"output\"]\n",
        "        result[\"source\"] = \"Dataset\"\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "m0pLUJi51ziW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test it"
      ],
      "metadata": {
        "id": "aGSEy19OFf3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    \"How do I update my mobile number?\",\n",
        "    \"What happens if I miss my EMI?\",\n",
        "    \"Tell me about interest rates\"\n",
        "]\n",
        "\n",
        "for q in tests:\n",
        "    r = similarity_search(q)\n",
        "    print(\"\\nQuery:\", q)\n",
        "    print(r)\n"
      ],
      "metadata": {
        "id": "w9CkkEYc121F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pe3oZFjXFihB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n"
      ],
      "metadata": {
        "id": "3Ww3LN9K21VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "sOZsoTRCGYdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "MODEL_NAME = \"google/flan-t5-base\"\n",
        "\n",
        "print(\"Loading model...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "print(\"Model loaded successfully.\")\n"
      ],
      "metadata": {
        "id": "4WHylr-X26rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genration Prompt"
      ],
      "metadata": {
        "id": "Wmuir-HPGpsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slm_generate(query, max_tokens=80):\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a BFSI banking assistant.\n",
        "\n",
        "Rules:\n",
        "- Answer only about banking, loans, EMI, payments.\n",
        "- If unsure, say \"Please contact customer support\".\n",
        "- Do NOT invent unrelated terms.\n",
        "\n",
        "Question: {query}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n"
      ],
      "metadata": {
        "id": "PwWjzawu36Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test The Model"
      ],
      "metadata": {
        "id": "7coXxmefGvep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(slm_generate(\"Explain how EMI is calculated\"))\n"
      ],
      "metadata": {
        "id": "aSqa2LvU3-oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_query(query):\n",
        "\n",
        "    # Tier-1: Dataset similarity\n",
        "    result = similarity_search(query, threshold=0.65)\n",
        "\n",
        "    if result[\"matched\"]:\n",
        "        return result[\"response\"], \"Dataset\"\n",
        "\n",
        "    # Tier-2: Local model\n",
        "    generated = slm_generate(query)\n",
        "    return generated, \"SLM\"\n"
      ],
      "metadata": {
        "id": "ZBZ06Idu_rz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Complete Flow"
      ],
      "metadata": {
        "id": "21vP37I4G_ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    \"How do I update my mobile number?\",\n",
        "    \"Explain EMI formula\"\n",
        "]\n",
        "\n",
        "for q in tests:\n",
        "    ans, src = answer_query(q)\n",
        "    print(\"\\nQuery:\", q)\n",
        "    print(\"Source:\", src)\n",
        "    print(\"Answer:\", ans)\n"
      ],
      "metadata": {
        "id": "3iecyOBG_612"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG Layer"
      ],
      "metadata": {
        "id": "6SdplcXwHHRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain faiss-cpu sentence-transformers\n"
      ],
      "metadata": {
        "id": "tmPwUH5MB7fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Knowldge Based Document"
      ],
      "metadata": {
        "id": "A5uh0IqqHUjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knowledge_docs = [\n",
        "\"\"\"\n",
        "EMI Formula:\n",
        "EMI = P × r × (1+r)^n / ((1+r)^n − 1)\n",
        "Where:\n",
        "P = principal loan amount\n",
        "r = monthly interest rate\n",
        "n = number of monthly installments\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "Interest Rates:\n",
        "Personal loan interest rates depend on customer credit profile.\n",
        "Rates typically range between 9% to 14% annually.\n",
        "Exact rate is decided during approval.\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "Late Payment Policy:\n",
        "If EMI is not paid on time, late payment charges and penalties may apply.\n",
        "This may also negatively affect credit score.\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "Loan Eligibility:\n",
        "Eligibility depends on income, credit score, employment stability, and repayment history.\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "Transaction Issues:\n",
        "Payments may take up to 24 hours to reflect. If not updated, customers should contact support with reference ID.\n",
        "\"\"\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "NPBcVMm8B_x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create FAISS knowledge index"
      ],
      "metadata": {
        "id": "CQK23-OYHdm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "rag_embed = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "doc_embeddings = rag_embed.encode(knowledge_docs)\n",
        "doc_embeddings = doc_embeddings / np.linalg.norm(doc_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "rag_index = faiss.IndexFlatIP(doc_embeddings.shape[1])\n",
        "rag_index.add(doc_embeddings)\n",
        "\n",
        "print(\"RAG knowledge base ready:\", rag_index.ntotal, \"documents\")\n"
      ],
      "metadata": {
        "id": "0mT_xUCcCEib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve relevant chunks"
      ],
      "metadata": {
        "id": "73PG8CxzHhcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_knowledge(query, top_k=2):\n",
        "\n",
        "    q_emb = rag_embed.encode([query])\n",
        "    q_emb = q_emb / np.linalg.norm(q_emb, axis=1, keepdims=True)\n",
        "\n",
        "    scores, indices = rag_index.search(q_emb, top_k)\n",
        "\n",
        "    contexts = [knowledge_docs[i] for i in indices[0]]\n",
        "\n",
        "    return \"\\n\".join(contexts)\n"
      ],
      "metadata": {
        "id": "LjAClF8RCJUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG Generation"
      ],
      "metadata": {
        "id": "CsE9ksMCHmB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_generate(query):\n",
        "\n",
        "    context = retrieve_knowledge(query)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a BFSI assistant.\n",
        "Answer ONLY using the context below.\n",
        "Do NOT invent information.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n"
      ],
      "metadata": {
        "id": "ieW1S1SUCO1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Router"
      ],
      "metadata": {
        "id": "EJu6RLUfHtz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_query(query):\n",
        "\n",
        "    # Tier 1 — Dataset\n",
        "    result = similarity_search(query)\n",
        "    if result[\"matched\"]:\n",
        "        return result[\"response\"], \"Dataset\"\n",
        "\n",
        "    # Tier 3 — Use RAG for finance/complex queries\n",
        "    finance_keywords = [\"emi\", \"interest\", \"rate\", \"penalty\", \"policy\", \"formula\", \"loan\"]\n",
        "\n",
        "    if any(word in query.lower() for word in finance_keywords):\n",
        "        return rag_generate(query), \"RAG\"\n",
        "\n",
        "    # Tier 2 — fallback SLM\n",
        "    return slm_generate(query), \"SLM\"\n"
      ],
      "metadata": {
        "id": "Frdcey6JCTD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "JePQjOqBHwjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    \"How do I update my mobile number?\",     # Tier-1\n",
        "    \"Explain EMI formula\",                  # Tier-3\n",
        "    \"What is loan eligibility?\",            # Tier-3\n",
        "    \"Hello how are you?\"                    # Tier-2\n",
        "]\n",
        "\n",
        "for q in tests:\n",
        "    ans, src = answer_query(q)\n",
        "    print(\"\\nQuery:\", q)\n",
        "    print(\"Source:\", src)\n",
        "    print(\"Answer:\", ans)\n"
      ],
      "metadata": {
        "id": "6srZcxdFCXbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardrail Rules"
      ],
      "metadata": {
        "id": "amgbMZQDH4d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "BLOCK_KEYWORDS = [\n",
        "    \"otp\",\n",
        "    \"password\",\n",
        "    \"pin\",\n",
        "    \"card number\",\n",
        "    \"account number\",\n",
        "    \"cvv\",\n",
        "    \"ssn\",\n",
        "    \"social security\"\n",
        "]\n",
        "\n",
        "OUT_OF_DOMAIN = [\n",
        "    \"politics\",\n",
        "    \"election\",\n",
        "    \"medical\",\n",
        "    \"disease\",\n",
        "    \"hack\",\n",
        "    \"illegal\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "zztI0H-5CqCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardrail Check Function"
      ],
      "metadata": {
        "id": "F_wQGonXH7xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def guardrail_check(query):\n",
        "\n",
        "    q = query.lower()\n",
        "\n",
        "    # Sensitive info\n",
        "    for word in BLOCK_KEYWORDS:\n",
        "        if word in q:\n",
        "            return False, \"Request involves sensitive information and cannot be processed.\"\n",
        "\n",
        "    # Out of domain\n",
        "    for word in OUT_OF_DOMAIN:\n",
        "        if word in q:\n",
        "            return False, \"This assistant supports only banking and financial queries.\"\n",
        "\n",
        "    return True, None\n"
      ],
      "metadata": {
        "id": "M1SJEEhiCtYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Safe Response Template"
      ],
      "metadata": {
        "id": "rkOKlap5IAqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_response(message):\n",
        "    return f\"⚠️ {message} Please contact official customer support for assistance.\"\n"
      ],
      "metadata": {
        "id": "Skfqxx_dCyAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Ruter"
      ],
      "metadata": {
        "id": "4hBn1cBuIDfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_query(query):\n",
        "\n",
        "    # Step 0 — Guardrails\n",
        "    safe, msg = guardrail_check(query)\n",
        "\n",
        "    if not safe:\n",
        "        return safe_response(msg), \"Guardrail\"\n",
        "\n",
        "    # Tier 1 — Dataset\n",
        "    result = similarity_search(query)\n",
        "\n",
        "    if result[\"matched\"]:\n",
        "        return result[\"response\"], \"Dataset\"\n",
        "\n",
        "    # Tier 3 — RAG (finance facts)\n",
        "    finance_keywords = [\"emi\", \"interest\", \"rate\", \"penalty\", \"policy\", \"loan\", \"formula\"]\n",
        "\n",
        "    if any(word in query.lower() for word in finance_keywords):\n",
        "        return rag_generate(query), \"RAG\"\n",
        "\n",
        "    # Tier 2 — SLM fallback\n",
        "    return slm_generate(query), \"SLM\"\n"
      ],
      "metadata": {
        "id": "eJLG2HE4C1mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Guardrails"
      ],
      "metadata": {
        "id": "KXy_wwohINN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    \"What is my account number?\",   # blocked\n",
        "    \"Send me OTP\",                 # blocked\n",
        "    \"Explain EMI formula\",         # RAG\n",
        "    \"How do I update mobile number?\" # Dataset\n",
        "]\n",
        "\n",
        "for q in tests:\n",
        "    ans, src = answer_query(q)\n",
        "    print(\"\\nQuery:\", q)\n",
        "    print(\"Source:\", src)\n",
        "    print(\"Answer:\", ans)\n"
      ],
      "metadata": {
        "id": "ZbzPlfjCC5Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n"
      ],
      "metadata": {
        "id": "s1lPCT8HDKkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Professional Chat UI"
      ],
      "metadata": {
        "id": "bWvrKTjzISoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat_interface(message, history):\n",
        "\n",
        "    answer, source = answer_query(message)\n",
        "\n",
        "    response_text = f\"{answer}\\n\\n(Source: {source})\"\n",
        "\n",
        "    history = history or []\n",
        "\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    history.append({\"role\": \"assistant\", \"content\": response_text})\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    gr.Markdown(\"#  BFSI AI Assistant\")\n",
        "    gr.Markdown(\"Loan • EMI • Interest • Account Support\")\n",
        "\n",
        "    chatbot = gr.Chatbot(type=\"messages\")\n",
        "\n",
        "    msg = gr.Textbox(placeholder=\"Ask your banking question...\")\n",
        "\n",
        "    msg.submit(chat_interface, [msg, chatbot], chatbot)\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "rCxWAq6wXTN3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}